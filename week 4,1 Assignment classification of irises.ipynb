{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "List of methods used this time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will use scikit-learn to train and estimate the following methods. We will not go into the details of each method at this stage. We will simply see that all of them can be easily used with the library, and that there are differences in the results of each method.\n",
    "\n",
    "Nearest neighbor method\n",
    "Logistic regression\n",
    "SVM\n",
    "Decision tree\n",
    "Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Problem1: Select features and categories for practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\Users\\\\sheku\\\\Downloads\\\\New folder\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "iris_data = load_iris()\n",
    "iris_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " extraction is taken place between virgicolor and virginica, and sepal_length and petal_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  petal_length  variety\n",
       "0           7.0           4.7        1\n",
       "1           6.4           4.5        1\n",
       "2           6.9           4.9        1\n",
       "3           5.5           4.0        1\n",
       "4           6.5           4.6        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(iris_data.data,columns=[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"]) \n",
    "y = pd.DataFrame(iris_data.target,columns=[\"variety\"])\n",
    "\n",
    "extracted_features = X[[\"sepal_length\",\"petal_length\"]] \n",
    "df = pd.concat([extracted_features,y], axis=1) \n",
    "subset = df.loc[(df['variety'] == 1)|(df['variety'] == 2)].reset_index(drop=True) \n",
    "subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Problem 2: Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-cd3d1b1d958a>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1 = figure.add_subplot(1,2,x_feature+1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure = plt.figure(figsize=(15, 5))\n",
    "variety_names = ['versicolor', 'virginica']\n",
    "x_features = ['sepal_length', 'petal_length']\n",
    "colors = ['orange','green']\n",
    "\n",
    "for x_feature in range(len(x_features)):\n",
    "    for a in range(len(variety_names)):\n",
    "        ax1 = figure.add_subplot(1,2,x_feature+1)\n",
    "        ax1.scatter(df[x_features[x_feature]],df['variety'],color=colors[a], label=variety_names[a], alpha=0.5)  \n",
    "    ax1.legend()\n",
    "    ax1.set_title(x_features[x_feature])\n",
    "    ax1.set_xlabel(x_features[x_feature])\n",
    "    ax1.set_ylabel('variety')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " box plot of the extracted data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " violin plot of the extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "for feature in range(len(x_features)):\n",
    "    x = []\n",
    "    for i in range(len(variety_names)):\n",
    "        target_variety = df.loc[df['variety']==i+1]\n",
    "        x.append(list(target_variety[x_features[feature]]))\n",
    "    ax2 = fig.add_subplot(1, 2, feature+1)\n",
    "    ax2.boxplot(x)\n",
    "    ax2.set_xticks([1, 2])\n",
    "    ax2.set_xticklabels(variety_names)\n",
    "    ax2.set_title(x_features[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A violin plot of the extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "for feature in range(len(x_features)):\n",
    "    x = []\n",
    "    for i in range(len(variety_names)):\n",
    "        target_variety = df.loc[df['variety']==i+1]\n",
    "        x.append(list(target_variety[x_features[feature]]))\n",
    "    ax2 = fig.add_subplot(1, 2, feature+1)\n",
    "    ax2.violinplot(x)\n",
    "    ax2.set_xticks([1, 2])\n",
    "    ax2.set_xticklabels(variety_names)\n",
    "    ax2.set_title(x_features[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Problem 3: Division of preprocessing, and training data and verification data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Spliting the training data and the validation data.\n",
    "The feature (explanatory variable) is stored in X and the correct answer (objective variable) is stored in an ndarray called y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(subset.loc[:,[\"sepal_length\",\"petal_length\"]])\n",
    "y = np.array(subset[\"variety\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Problem 4: Pretreatment/Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_trans = scaler.transform(X_train)\n",
    "X_test_trans = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Problem 5: Learning and estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred3 =  [2 2 2 1 1 1 2 2 1 1 1 1 2 2 2 1 1 1 1 1 2 1 1 1 2]\n",
      "pred5 =  [2 2 2 1 1 1 1 2 1 1 1 1 1 2 2 1 1 1 1 1 2 1 1 1 2]\n",
      "pred1 =  [2 2 2 1 1 1 1 2 1 1 1 1 1 2 2 1 1 1 1 1 2 1 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k_neigh_3 = KNeighborsClassifier(n_neighbors=3)\n",
    "k_neigh_3.fit(X_train_trans, y_train.ravel())\n",
    "pred_3 = k_neigh_3.predict(X_test_trans)\n",
    "print(\"pred3 = \", pred_3)\n",
    "\n",
    "k_neigh_5 = KNeighborsClassifier(n_neighbors=5)\n",
    "k_neigh_5.fit(X_train_trans, y_train.ravel())\n",
    "pred_5 = k_neigh_5.predict(X_test_trans)\n",
    "print(\"pred5 = \", pred_5)\n",
    "\n",
    "k_neigh_1 = KNeighborsClassifier(n_neighbors=1)\n",
    "k_neigh_1.fit(X_train_trans, y_train.ravel())\n",
    "pred_1 = k_neigh_1.predict(X_test_trans)\n",
    "print(\"pred1 = \", pred_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Problem 6: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions of  knn3\n",
      "accuracy = 0.8\n",
      "precision = [0.8 0.8]\n",
      "recall = [0.85714286 0.72727273]\n",
      "f1 score = [0.82758621 0.76190476]\n",
      "confusion matrix = [[12  2]\n",
      " [ 3  8]]\n",
      "-------------------------------------------------------------------------------------\n",
      "predictions of  knn5\n",
      "accuracy = 0.8\n",
      "precision = [0.76470588 0.875     ]\n",
      "recall = [0.92857143 0.63636364]\n",
      "f1 score = [0.83870968 0.73684211]\n",
      "confusion matrix = [[13  1]\n",
      " [ 4  7]]\n",
      "-------------------------------------------------------------------------------------\n",
      "predictions of  knn1\n",
      "accuracy = 0.8\n",
      "precision = [0.8 0.8]\n",
      "recall = [0.85714286 0.72727273]\n",
      "f1 score = [0.82758621 0.76190476]\n",
      "confusion matrix = [[12  2]\n",
      " [ 3  8]]\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix\n",
    "\n",
    "predictions = [pred_3, pred_5, pred_1]\n",
    "keys = [\"knn3\",\"knn5\",\"knn1\"]\n",
    "\n",
    "for a,prediction in enumerate(predictions,0):\n",
    "    print(\"predictions of \", keys[a])\n",
    "    print(\"accuracy =\", accuracy_score(y_true=y_test, y_pred=prediction))\n",
    "    print(\"precision =\", precision_score(y_true=y_test, y_pred=prediction,average=None))    \n",
    "    print(\"recall =\", recall_score(y_true=y_test, y_pred=prediction,average=None))  \n",
    "    print(\"f1 score =\", f1_score(y_true=y_test, y_pred=prediction,average=None)) \n",
    "    print(\"confusion matrix =\", confusion_matrix(y_true=y_test, y_pred=prediction)) \n",
    "    nprint(\"-------------------------------------------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Problem 7: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "def decision_region(X, y, model, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['versicolor', 'virginica']):\n",
    "    # setting\n",
    "    scatter_color = ['green', 'blue']\n",
    "    contourf_color = ['brown', 'skyblue']\n",
    "    n_class = 2\n",
    "    # pred\n",
    "    mesh_f0, mesh_f1  = np.meshgrid(np.arange(np.min(X[:,0])-0.5, np.max(X[:,0])+0.5, step), np.arange(np.min(X[:,1])-0.5, np.max(X[:,1])+0.5, step))\n",
    "    mesh = np.c_[np.ravel(mesh_f0),np.ravel(mesh_f1)]\n",
    "    y_pred = model.predict(mesh).reshape(mesh_f0.shape)\n",
    "    # plot\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.contourf(mesh_f0, mesh_f1, y_pred, n_class-1, cmap=ListedColormap(contourf_color))\n",
    "    plt.contour(mesh_f0, mesh_f1, y_pred, n_class-1, colors='y', linewidths=3, alpha=0.5)\n",
    "    for i, target in enumerate(set(y)):\n",
    "        plt.scatter(X[y==target][:, 0], X[y==target][:, 1], s=80, color=scatter_color[i], label=target_names[i], marker='o')\n",
    "    patches = [mpatches.Patch(color=scatter_color[i], label=target_names[i]) for i in range(n_class)]\n",
    "    plt.legend(handles=patches)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "models = [k_neigh_3, k_neigh_5, k_neigh_1]\n",
    "for a,model in enumerate(models, 1):\n",
    "    decision_region(X_test_trans, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem 8: Learning by other methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " estimate and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_outputs(title,pred,model,std):\n",
    "    print(title)\n",
    "    print(\"pred = \", pred)\n",
    "    print(\"accuracy =\", accuracy_score(y_true=y_test, y_pred=pred))\n",
    "    print(\"precision =\", precision_score(y_true=y_test, y_pred=pred,average=None))    \n",
    "    print(\"recall =\", recall_score(y_true=y_test, y_pred=pred,average=None))  \n",
    "    print(\"f1 score =\", f1_score(y_true=y_test, y_pred=pred,average=None)) \n",
    "    print(\"confusion matrix =\", confusion_matrix(y_true=y_test, y_pred=pred)) \n",
    "    if (std == True):\n",
    "        decision_region(X_test_trans, y_test, model)\n",
    "    else:\n",
    "        decision_region(X_test, y_test, model)\n",
    "    print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " visualize all the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lR_fit = LogisticRegression(random_state=0).fit(X_train_trans, y_train)\n",
    "lR_predict = lR_fit.predict(X_test_trans)\n",
    "display_outputs('Logical Regression',lR_predict,lR_fit,std=True)\n",
    "\n",
    "#for SVM\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X_train_trans, y_train)\n",
    "clf_pred = clf.predict(X_test_trans)\n",
    "display_outputs('SVM',clf_pred,clf,std=True)\n",
    "\n",
    "#for Decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dTC = DecisionTreeClassifier(random_state=0)\n",
    "dTC.fit(X_train_trans, y_train)\n",
    "dTC_pred = dTC.predict(X_test_trans)\n",
    "display_outputs('Decision tree',dTC_pred,dTC,std=True)\n",
    "\n",
    "#for Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rFC = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rFC.fit(X_train_trans, y_train)\n",
    "rFC_pred = rFC.predict(X_test_trans)\n",
    "display_outputs('Random Forest',rFC_pred,rFC,std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison: When we look at all method we will see that they are all similar in the prediction results, but SVM and logical regression has the highest precision results which to me makes their results more precise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 9: Advanced task Comparison with and without standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# knn\n",
    "k_neigh_3_2 = KNeighborsClassifier(n_neighbors=3)\n",
    "k_neigh_3_2.fit(X_train, y_train.ravel())\n",
    "pred_3_2 = k_neigh_3_2.predict(X_test)\n",
    "display_outputs('Knn',pred_3_2,k_neigh_3_2,std=False)\n",
    "\n",
    "# LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lR_fit = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "lR_predict = lR_fit.predict(X_test)\n",
    "display_outputs('Logistic regression',lR_predict,lR_fit,std=False)\n",
    "\n",
    "# SVM\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X_train, y_train)\n",
    "clf_pred = clf.predict(X_test)\n",
    "display_outputs('SVM',clf_pred,clf,std=False)\n",
    "\n",
    "# Decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dTC = DecisionTreeClassifier(random_state=0)\n",
    "dTC.fit(X_train, y_train)\n",
    "dTC_pred = dTC.predict(X_test)\n",
    "display_outputs('Decision tree',dTC_pred,dTC,std=False)\n",
    "\n",
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rFC = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rFC.fit(X_train, y_train)\n",
    "rFC_pred = rFC.predict(X_test)\n",
    "display_outputs('Random forest',rFC_pred,rFC,std=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Problem 10: Advanced task Method with high accuracy using all objective variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_region_2(X, y, model, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['versicolor', 'virginica','setosa']):\n",
    "    # setting\n",
    "    scatter_color = ['red', 'blue', 'green']\n",
    "    contourf_color = ['pink', 'skyblue', 'lightgreen']\n",
    "    n_class = 3\n",
    "    # predition\n",
    "    mesh_f0, mesh_f1  = np.meshgrid(np.arange(np.min(X[:,0])-0.5, np.max(X[:,0])+0.5, step), np.arange(np.min(X[:,1])-0.5, np.max(X[:,1])+0.5, step))\n",
    "    mesh = np.c_[np.ravel(mesh_f0),np.ravel(mesh_f1)]\n",
    "    y_pred = model.predict(mesh).reshape(mesh_f0.shape)\n",
    "    # plot\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.contourf(mesh_f0, mesh_f1, y_pred, n_class-1, cmap=ListedColormap(contourf_color))\n",
    "    plt.contour(mesh_f0, mesh_f1, y_pred, n_class-1, colors='y', linewidths=3, alpha=0.5)\n",
    "    for i, target in enumerate(set(y)):\n",
    "        plt.scatter(X[y==target][:, 0], X[y==target][:, 1], s=80, color=scatter_color[i], label=target_names[i], marker='o')\n",
    "    patches = [mpatches.Patch(color=scatter_color[i], label=target_names[i]) for i in range(n_class)]\n",
    "    plt.legend(handles=patches)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def display_outputs_2(title,pred,model,std):\n",
    "    print(title)\n",
    "    print(\"pred = \", pred)\n",
    "    print(\"accuracy =\", accuracy_score(y_true=y_test, y_pred=pred))\n",
    "    print(\"precision =\", precision_score(y_true=y_test, y_pred=pred,average=None))    \n",
    "    print(\"recall =\", recall_score(y_true=y_test, y_pred=pred,average=None))  \n",
    "    print(\"f1 score =\", f1_score(y_true=y_test, y_pred=pred,average=None)) \n",
    "    print(\"confusion matrix =\", confusion_matrix(y_true=y_test, y_pred=pred)) \n",
    "    if (std == True):\n",
    "        decision_region_2(X_test_trans, y_test, model)\n",
    "    else:\n",
    "        decision_region_2(X_test, y_test, model)\n",
    "    print(\"------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "# new variables with all targets\n",
    "X2 = df.iloc[:, :-1].values\n",
    "y2 = df.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.25, random_state=42)\n",
    "\n",
    "# knn\n",
    "k_neigh_3_2 = KNeighborsClassifier(n_neighbors=3)\n",
    "k_neigh_3_2.fit(X_train, y_train.ravel())\n",
    "pred_3_2 = k_neigh_3_2.predict(X_test)\n",
    "display_outputs_2('Knn',pred_3_2,k_neigh_3_2,std=False)\n",
    "\n",
    "# LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lR_fit = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "lR_predict = lR_fit.predict(X_test)\n",
    "display_outputs_2('Logistic regression',lR_predict,lR_fit,std=False)\n",
    "\n",
    "# SVM\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X_train, y_train)\n",
    "clf_pred = clf.predict(X_test)\n",
    "display_outputs_2('SVM',clf_pred,clf,std=False)\n",
    "\n",
    "# Decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dTC = DecisionTreeClassifier(random_state=0)\n",
    "dTC.fit(X_train, y_train)\n",
    "dTC_pred = dTC.predict(X_test)\n",
    "display_outputs_2('Decision tree',dTC_pred,dTC,std=False)\n",
    "\n",
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rFC = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rFC.fit(X_train, y_train)\n",
    "rFC_pred = rFC.predict(X_test)\n",
    "display_outputs_2('Random forest',rFC_pred,rFC,std=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
