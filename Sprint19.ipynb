{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "yNa2fl8ekQQA"
   },
   "outputs": [],
   "source": [
    "mkdir .kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "jiIssAUnkoRq",
    "outputId": "3487f77c-325d-4d22-f810-5cf6cffe3bcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle.json\n"
     ]
    }
   ],
   "source": [
    "ls .kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "MsmyZDh2jmGr"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "token = {\"username\":\"andrewmaadabrima\",\"key\":\"ac28103f1ac56d0bcd1ec22070c674fc\"}\n",
    "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
    "    json.dump(token, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "sG7Aye1UkwBx"
   },
   "outputs": [],
   "source": [
    "!chmod 600 /content/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "rKFHWDkFk1Cy"
   },
   "outputs": [],
   "source": [
    "!cp -R /content/.kaggle/kaggle.json /root/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "0c5jPmrPlBGC",
    "outputId": "5e9c5660-110c-40c5-dc50-15efc8ec89f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/My Drive/')\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZCgKZBjylAoJ"
   },
   "outputs": [],
   "source": [
    "!kaggle competitions download -c tgs-salt-identification-challenge --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxKPX4fwgYJc"
   },
   "source": [
    "## Problem 1 Learning / estimation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5WJTMgbGm6eU"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import glob\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from __future__ import print_function\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def unet(pretrained_weights = None,input_size = (256,256,1)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs, conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    #model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "    \tmodel.load_weights(pretrained_weights)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "yIRPcuNxBsVQ"
   },
   "outputs": [],
   "source": [
    "def adjustData(img,mask,flag_multi_class,num_class):\n",
    "    if(flag_multi_class):\n",
    "        img = img / 255\n",
    "        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n",
    "        new_mask = np.zeros(mask.shape + (num_class,))\n",
    "        for i in range(num_class):\n",
    "            #for one pixel in the image, find the class in mask and convert it into one-hot vector\n",
    "            #index = np.where(mask == i)\n",
    "            #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)\n",
    "            #new_mask[index_mask] = 1\n",
    "            new_mask[mask == i,i] = 1\n",
    "        new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n",
    "        mask = new_mask\n",
    "    elif(np.max(img) > 1):\n",
    "        img = img / 255\n",
    "        mask = mask /255\n",
    "        mask[mask > 0.5] = 1\n",
    "        mask[mask <= 0.5] = 0\n",
    "    return (img,mask)\n",
    "\n",
    "def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n",
    "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
    "                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (256,256),seed = 1):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    image_datagen = ImageDataGenerator(**aug_dict)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        seed = seed)\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        seed = seed)\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img,mask) in train_generator:\n",
    "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
    "        yield (img,mask)\n",
    "\n",
    "\n",
    "def testGenerator(test_files,num_image = 30,target_size = (256,256),flag_multi_class = False,as_gray = True):\n",
    "    for path in test_files:\n",
    "        img = io.imread(path, as_gray = as_gray)\n",
    "        img = img / 255\n",
    "        img = trans.resize(img,target_size)\n",
    "        img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n",
    "        img = np.reshape(img,(1,)+img.shape)\n",
    "        yield img        \n",
    "\n",
    "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
    "        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f5aDHOQMDd-"
   },
   "source": [
    "### study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "F04xPKUhm7b2",
    "outputId": "710e8e2f-010a-4077-80b6-e5c28323d949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 1 classes.\n",
      "Found 4000 images belonging to 1 classes.\n",
      "Epoch 1/5\n",
      "   2/2000 [..............................] - ETA: 4:54 - loss: 0.4616 - accuracy: 0.9703WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0487s vs `on_train_batch_end` time: 0.1010s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0487s vs `on_train_batch_end` time: 0.1010s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - ETA: 0s - loss: 0.5847 - accuracy: 0.7508\n",
      "Epoch 00001: loss improved from inf to 0.58471, saving model to unet_Salt.hdf5\n",
      "2000/2000 [==============================] - 313s 157ms/step - loss: 0.5847 - accuracy: 0.7508\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.5782 - accuracy: 0.7504\n",
      "Epoch 00002: loss improved from 0.58471 to 0.57823, saving model to unet_Salt.hdf5\n",
      "2000/2000 [==============================] - 313s 156ms/step - loss: 0.5782 - accuracy: 0.7504\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.5735 - accuracy: 0.7504\n",
      "Epoch 00003: loss improved from 0.57823 to 0.57348, saving model to unet_Salt.hdf5\n",
      "2000/2000 [==============================] - 314s 157ms/step - loss: 0.5735 - accuracy: 0.7504\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.5698 - accuracy: 0.7507\n",
      "Epoch 00004: loss improved from 0.57348 to 0.56983, saving model to unet_Salt.hdf5\n",
      "2000/2000 [==============================] - 315s 157ms/step - loss: 0.5698 - accuracy: 0.7507\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.5677 - accuracy: 0.7504\n",
      "Epoch 00005: loss improved from 0.56983 to 0.56766, saving model to unet_Salt.hdf5\n",
      "2000/2000 [==============================] - 315s 157ms/step - loss: 0.5677 - accuracy: 0.7504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f47c91beb38>"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "myGene = trainGenerator(2,'./train/','images','masks',data_gen_args,save_to_dir = None)\n",
    "model = unet(\"unet_Salt.hdf5\")\n",
    "model_checkpoint = ModelCheckpoint('unet_Salt.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "model.fit_generator(myGene,steps_per_epoch=2000,epochs=5,callbacks=[model_checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "GI5g-FARi7tM"
   },
   "outputs": [],
   "source": [
    "test_files = glob.glob(\"./test/images/*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZd1fLVCNQIk"
   },
   "outputs": [],
   "source": [
    "testGene = testGenerator(test_files)\n",
    "results = model.predict_generator(testGene,30,verbose=1)\n",
    "saveResult(\"./test/results\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ajr4BYyKuXFa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "\n",
    "result_files = glob.glob(\"./test/results/*\")\n",
    "\n",
    "for i, file in enumerate(result_files):\n",
    "  img = Image.open(file)\n",
    "  print(np.array(img))\n",
    "  plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "  plt.subplot(3, 10, i+1)\n",
    "\n",
    "plt.show(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsxdvGy3gx5O"
   },
   "source": [
    "## Problem 2 Code reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGqQTWMNg0e7"
   },
   "source": [
    "### What is U-net\n",
    "U-net is one of the FCNs and is a network for estimating image segmentation.\n",
    "Published in 2015 for image segmentation in biomedical sciences.\n",
    "At that time, high recognition accuracy was achieved by amplifying the data with a small amount of supervised learning by data Augumentation and using it efficiently for learning.\n",
    "\n",
    "### FCN\n",
    "A general CNN is composed of a convolutional layer and a fully connected layer, but the fully connected layer is replaced with a convolutional layer. By replacing the fully connected layer, the output of \"what is the object\" becomes an image of \"where is the object\".\n",
    "\n",
    "### skip-connection\n",
    "As the convolution process is added, the network extracts features about \"what the object is\", but the information about \"where the object is\" is lost due to the influence of Pooling. The location information may not be restored even if deconvolution is performed after the convolution process is performed. Skip-connection solves this problem. After convolution, the feature map is retained and added to the deconvolution image later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9xLVsrSvSuk"
   },
   "source": [
    "#### Code reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kaqQ0IlFBT4"
   },
   "source": [
    "### U-net\n",
    "```python\n",
    "def unet(pretrained_weights = None,input_size = (256,256,1)):\n",
    "    #Input layer=======================================================\n",
    "    inputs = Input(input_size)\n",
    "    #1st layer=======================================================\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    #MaxPooling==================================================\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    #2nd layer=======================================================\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    #MaxPooling==================================================\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    #n3rd layer=======================================================\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    #MaxPooling==================================================\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    #4th layer=======================================================\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    #MaxPooling==================================================\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    #5th layer=======================================================\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    #UpConv======================================================\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    #SkipConnection(4th layer)========================================\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    #4th layer(right)=================================================\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    #upconv=======================================================\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    #SkipConnection(3rd layer)========================================\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    #3rd layer(right)=================================================\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    #upconv=======================================================\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    #SkipConnection(2nd layer)========================================\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    #2nd layer(right)=================================================\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    #upconv=======================================================\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    #SkipConnection(1st layer)========================================\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    #1st layer(right)=================================================\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    #output=======================================================\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs, conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNRthigtgxYW0r9+KUyXzSk",
   "collapsed_sections": [],
   "mount_file_id": "12kXaPOF_6KX9u2-JpmFAHGtj-6mLDokE",
   "name": "Sprint19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
